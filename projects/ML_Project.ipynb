{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21b9a056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871fd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fashion = keras.datasets.fashion_mnist\n",
    "(a_train_full, b_train_full), (a_test, b_test) = dataset_fashion.load_data()\n",
    "\n",
    "a_train, a_valid, b_train, b_valid = train_test_split(a_train_full, b_train_full,\n",
    "                                                      test_size=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348e90a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training , testing and validation datasets\n",
    "a_train = a_train / 255.0\n",
    "a_valid = a_valid /255.0\n",
    "a_test = a_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d73922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 28, 30)       870         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 28, 30)      120         ['dense[0][0]']                  \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 28, 60)       1860        ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 28, 60)      240         ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28, 88)       0           ['input_1[0][0]',                \n",
      "                                                                  'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2464)         0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2464)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           24650       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 27,740\n",
      "Trainable params: 27,560\n",
      "Non-trainable params: 180\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BUILDING THE MODEL-1\n",
    "i_d = keras.layers.Input(shape=a_train.shape[1:])\n",
    "l1 = keras.layers.Dense(30, activation='relu')(i_d)\n",
    "b1 = keras.layers.BatchNormalization()(l1)\n",
    "l2 = keras.layers.Dense(60, activation='relu')(b1)\n",
    "b2 = keras.layers.BatchNormalization()(l2)\n",
    "c = keras.layers.Concatenate()([i_d, b2])\n",
    "f = keras.layers.Flatten()(c)\n",
    "d = keras.layers.Dropout(0.3)(f)\n",
    "result = keras.layers.Dense(10, activation='softmax')(d)\n",
    "model1 = keras.models.Model(inputs=[i_d], outputs=[result])\n",
    "\n",
    "model1.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "def0a7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.5134 - accuracy: 0.8236 - val_loss: 0.3855 - val_accuracy: 0.8596\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3983 - accuracy: 0.8573 - val_loss: 0.3348 - val_accuracy: 0.8828\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3660 - accuracy: 0.8676 - val_loss: 0.3438 - val_accuracy: 0.8778\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3462 - accuracy: 0.8770 - val_loss: 0.3371 - val_accuracy: 0.8824\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3331 - accuracy: 0.8797 - val_loss: 0.3099 - val_accuracy: 0.8908\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3214 - accuracy: 0.8826 - val_loss: 0.3085 - val_accuracy: 0.8906\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3144 - accuracy: 0.8846 - val_loss: 0.3130 - val_accuracy: 0.8918\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3103 - accuracy: 0.8877 - val_loss: 0.3129 - val_accuracy: 0.8876\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.3036 - accuracy: 0.8892 - val_loss: 0.3005 - val_accuracy: 0.8926\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2961 - accuracy: 0.8923 - val_loss: 0.2897 - val_accuracy: 0.8964\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2936 - accuracy: 0.8936 - val_loss: 0.3080 - val_accuracy: 0.8896\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2904 - accuracy: 0.8936 - val_loss: 0.2952 - val_accuracy: 0.8990\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2885 - accuracy: 0.8945 - val_loss: 0.2953 - val_accuracy: 0.8988\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2820 - accuracy: 0.8962 - val_loss: 0.3323 - val_accuracy: 0.8818\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2829 - accuracy: 0.8954 - val_loss: 0.2948 - val_accuracy: 0.8992\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2786 - accuracy: 0.8970 - val_loss: 0.2934 - val_accuracy: 0.9016\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2735 - accuracy: 0.8999 - val_loss: 0.3087 - val_accuracy: 0.8936\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 11s 7ms/step - loss: 0.2722 - accuracy: 0.8996 - val_loss: 0.3108 - val_accuracy: 0.8918\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2674 - accuracy: 0.9025 - val_loss: 0.2944 - val_accuracy: 0.8978\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2690 - accuracy: 0.9014 - val_loss: 0.2884 - val_accuracy: 0.9022\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2653 - accuracy: 0.9015 - val_loss: 0.3287 - val_accuracy: 0.8894\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2660 - accuracy: 0.9028 - val_loss: 0.3030 - val_accuracy: 0.8944\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2597 - accuracy: 0.9049 - val_loss: 0.3078 - val_accuracy: 0.8960\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2619 - accuracy: 0.9038 - val_loss: 0.2877 - val_accuracy: 0.9048\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2598 - accuracy: 0.9049 - val_loss: 0.2825 - val_accuracy: 0.9056\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2588 - accuracy: 0.9054 - val_loss: 0.3057 - val_accuracy: 0.8942\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.2562 - accuracy: 0.9049 - val_loss: 0.2926 - val_accuracy: 0.9006\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 13s 7ms/step - loss: 0.2583 - accuracy: 0.9045 - val_loss: 0.2850 - val_accuracy: 0.9046\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2546 - accuracy: 0.9059 - val_loss: 0.3023 - val_accuracy: 0.8988\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 12s 7ms/step - loss: 0.2515 - accuracy: 0.9071 - val_loss: 0.2867 - val_accuracy: 0.9034\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model1.fit(a_train, b_train, epochs=30,\n",
    "                    validation_data=(a_valid, b_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e6e5bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  90.71090817451477\n",
      "Validation Accuracy:  90.34000039100647\n",
      "Test Accuracy:  88.95999789237976\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = model1.evaluate(a_test, b_test, verbose=0)\n",
    "print(\"Train Accuracy: \", history.history['accuracy'][-1] * 100)\n",
    "print(\"Validation Accuracy: \", history.history['val_accuracy'][-1] * 100)\n",
    "print(\"Test Accuracy: \", test_accuracy * 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedfb1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 28, 80)       2320        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 28, 80)      320         ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 28, 96)       7776        ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 28, 96)      384         ['dense_4[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 28, 124)      0           ['input_2[0][0]',                \n",
      "                                                                  'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 3472)         0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 3472)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           34730       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 45,530\n",
      "Trainable params: 45,178\n",
      "Non-trainable params: 352\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BUILDING THE MODEL 2\n",
    "\n",
    "i_d = keras.layers.Input(shape=a_train.shape[1:])\n",
    "l1 = keras.layers.Dense(80, activation='relu')(i_d)\n",
    "b1 = keras.layers.BatchNormalization()(l1)\n",
    "l2 = keras.layers.Dense(96, activation='relu')(b1)\n",
    "b2 = keras.layers.BatchNormalization()(l2)\n",
    "c = keras.layers.Concatenate()([i_d, b2])\n",
    "f = keras.layers.Flatten()(c)\n",
    "d = keras.layers.Dropout(0.6)(f)\n",
    "result = keras.layers.Dense(10, activation='softmax')(d)\n",
    "model2 = keras.models.Model(inputs=[i_d], outputs=[result])\n",
    "\n",
    "model2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc787fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.6193 - accuracy: 0.8082 - val_loss: 0.3559 - val_accuracy: 0.8756\n",
      "Epoch 2/35\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4606 - accuracy: 0.8447 - val_loss: 0.3327 - val_accuracy: 0.8874\n",
      "Epoch 3/35\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.4186 - accuracy: 0.8551 - val_loss: 0.3399 - val_accuracy: 0.8808\n",
      "Epoch 4/35\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.3905 - accuracy: 0.8639 - val_loss: 0.3408 - val_accuracy: 0.8772\n",
      "Epoch 5/35\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3703 - accuracy: 0.8687 - val_loss: 0.3176 - val_accuracy: 0.8894\n",
      "Epoch 6/35\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3591 - accuracy: 0.8710 - val_loss: 0.3161 - val_accuracy: 0.8908\n",
      "Epoch 7/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3501 - accuracy: 0.8731 - val_loss: 0.3085 - val_accuracy: 0.8938\n",
      "Epoch 8/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3403 - accuracy: 0.8771 - val_loss: 0.3052 - val_accuracy: 0.8930\n",
      "Epoch 9/35\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.3354 - accuracy: 0.8788 - val_loss: 0.2974 - val_accuracy: 0.8972\n",
      "Epoch 10/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3280 - accuracy: 0.8813 - val_loss: 0.3013 - val_accuracy: 0.8948\n",
      "Epoch 11/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3199 - accuracy: 0.8851 - val_loss: 0.2994 - val_accuracy: 0.8974\n",
      "Epoch 12/35\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.3177 - accuracy: 0.8847 - val_loss: 0.2880 - val_accuracy: 0.9020\n",
      "Epoch 13/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3151 - accuracy: 0.8866 - val_loss: 0.2941 - val_accuracy: 0.8984\n",
      "Epoch 14/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3091 - accuracy: 0.8865 - val_loss: 0.2795 - val_accuracy: 0.9004\n",
      "Epoch 15/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3060 - accuracy: 0.8881 - val_loss: 0.2753 - val_accuracy: 0.9050\n",
      "Epoch 16/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3012 - accuracy: 0.8898 - val_loss: 0.2789 - val_accuracy: 0.9022\n",
      "Epoch 17/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3006 - accuracy: 0.8900 - val_loss: 0.2852 - val_accuracy: 0.9006\n",
      "Epoch 18/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.3016 - accuracy: 0.8900 - val_loss: 0.2931 - val_accuracy: 0.8962\n",
      "Epoch 19/35\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.2937 - accuracy: 0.8942 - val_loss: 0.3076 - val_accuracy: 0.8928\n",
      "Epoch 20/35\n",
      "1719/1719 [==============================] - 18s 10ms/step - loss: 0.2921 - accuracy: 0.8937 - val_loss: 0.2842 - val_accuracy: 0.8974\n",
      "Epoch 21/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2935 - accuracy: 0.8937 - val_loss: 0.2733 - val_accuracy: 0.9056\n",
      "Epoch 22/35\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2877 - accuracy: 0.8950 - val_loss: 0.2902 - val_accuracy: 0.9016\n",
      "Epoch 23/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2874 - accuracy: 0.8947 - val_loss: 0.2788 - val_accuracy: 0.9044\n",
      "Epoch 24/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2860 - accuracy: 0.8958 - val_loss: 0.2750 - val_accuracy: 0.9056\n",
      "Epoch 25/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2811 - accuracy: 0.8977 - val_loss: 0.2828 - val_accuracy: 0.9022\n",
      "Epoch 26/35\n",
      "1719/1719 [==============================] - 18s 11ms/step - loss: 0.2831 - accuracy: 0.8970 - val_loss: 0.2865 - val_accuracy: 0.9022\n",
      "Epoch 27/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2806 - accuracy: 0.8996 - val_loss: 0.2788 - val_accuracy: 0.9066\n",
      "Epoch 28/35\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2836 - accuracy: 0.8969 - val_loss: 0.2681 - val_accuracy: 0.9100\n",
      "Epoch 29/35\n",
      "1719/1719 [==============================] - 13s 8ms/step - loss: 0.2786 - accuracy: 0.8981 - val_loss: 0.2766 - val_accuracy: 0.9038\n",
      "Epoch 30/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2760 - accuracy: 0.8997 - val_loss: 0.2741 - val_accuracy: 0.9062\n",
      "Epoch 31/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2767 - accuracy: 0.8980 - val_loss: 0.2799 - val_accuracy: 0.9040\n",
      "Epoch 32/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2739 - accuracy: 0.9009 - val_loss: 0.2831 - val_accuracy: 0.9040\n",
      "Epoch 33/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2743 - accuracy: 0.9005 - val_loss: 0.3364 - val_accuracy: 0.8830\n",
      "Epoch 34/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2750 - accuracy: 0.8989 - val_loss: 0.2724 - val_accuracy: 0.9070\n",
      "Epoch 35/35\n",
      "1719/1719 [==============================] - 19s 11ms/step - loss: 0.2747 - accuracy: 0.8993 - val_loss: 0.2699 - val_accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model2.fit(a_train, b_train, epochs=35,\n",
    "                    validation_data=(a_valid, b_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820378ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  89.93090987205505\n",
      "Validation Accuracy:  91.21999740600586\n",
      "Test Accuracy:  89.70000147819519\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = model2.evaluate(a_test, b_test, verbose=0)\n",
    "print(\"Train Accuracy: \", history.history['accuracy'][-1] * 100)\n",
    "print(\"Validation Accuracy: \", history.history['val_accuracy'][-1] * 100)\n",
    "print(\"Test Accuracy: \", test_accuracy * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a48a8f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 28, 28)]     0           []                               \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 28, 80)       2320        ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 28, 80)      320         ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 28, 240)      19440       ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 28, 240)     960         ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 28, 500)      120500      ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 28, 500)     2000        ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 28, 528)      0           ['input_3[0][0]',                \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 14784)        0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 14784)        0           ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 10)           147850      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 293,390\n",
      "Trainable params: 291,750\n",
      "Non-trainable params: 1,640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#BULDING THE MODEL-3\n",
    "\n",
    "i_d = keras.layers.Input(shape=a_train.shape[1:])\n",
    "l1 = keras.layers.Dense(80, activation='relu')(i_d)\n",
    "b1 = keras.layers.BatchNormalization()(l1)\n",
    "l2 = keras.layers.Dense(240, activation='relu')(b1)\n",
    "b2 = keras.layers.BatchNormalization()(l2)\n",
    "l3 = keras.layers.Dense(500, activation='relu')(b2)\n",
    "b3 = keras.layers.BatchNormalization()(l3)\n",
    "c = keras.layers.Concatenate()([i_d, b3])\n",
    "f = keras.layers.Flatten()(c)\n",
    "d = keras.layers.Dropout(0.5)(f)\n",
    "result = keras.layers.Dense(10, activation='softmax')(d)\n",
    "model3 = keras.models.Model(inputs=[i_d], outputs=[result])\n",
    "\n",
    "model3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca7d2a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 63s 35ms/step - loss: 0.9681 - accuracy: 0.8067 - val_loss: 0.6961 - val_accuracy: 0.8438\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.6622 - accuracy: 0.8439 - val_loss: 0.4772 - val_accuracy: 0.8828\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 68s 39ms/step - loss: 0.5300 - accuracy: 0.8575 - val_loss: 0.4176 - val_accuracy: 0.8812\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 66s 38ms/step - loss: 0.4767 - accuracy: 0.8666 - val_loss: 0.3984 - val_accuracy: 0.8792\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.4251 - accuracy: 0.8752 - val_loss: 0.3831 - val_accuracy: 0.8820\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 65s 38ms/step - loss: 0.3923 - accuracy: 0.8775 - val_loss: 0.3434 - val_accuracy: 0.8948\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 65s 38ms/step - loss: 0.3658 - accuracy: 0.8820 - val_loss: 0.3544 - val_accuracy: 0.8900\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.3426 - accuracy: 0.8880 - val_loss: 0.3310 - val_accuracy: 0.8954\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.3158 - accuracy: 0.8942 - val_loss: 0.3369 - val_accuracy: 0.8936\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.3011 - accuracy: 0.8967 - val_loss: 0.3184 - val_accuracy: 0.9026\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 66s 38ms/step - loss: 0.2859 - accuracy: 0.9008 - val_loss: 0.3137 - val_accuracy: 0.8978\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 59s 34ms/step - loss: 0.2767 - accuracy: 0.9045 - val_loss: 0.3209 - val_accuracy: 0.8932\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 61s 36ms/step - loss: 0.2633 - accuracy: 0.9073 - val_loss: 0.3532 - val_accuracy: 0.8822\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.2519 - accuracy: 0.9115 - val_loss: 0.3182 - val_accuracy: 0.8944\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.2446 - accuracy: 0.9130 - val_loss: 0.3129 - val_accuracy: 0.8990\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.2353 - accuracy: 0.9166 - val_loss: 0.3109 - val_accuracy: 0.8980\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.2326 - accuracy: 0.9168 - val_loss: 0.3290 - val_accuracy: 0.8990\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - 61s 36ms/step - loss: 0.2222 - accuracy: 0.9210 - val_loss: 0.3282 - val_accuracy: 0.8996\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.2153 - accuracy: 0.9226 - val_loss: 0.3350 - val_accuracy: 0.9028\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.2056 - accuracy: 0.9254 - val_loss: 0.3544 - val_accuracy: 0.8926\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.2063 - accuracy: 0.9263 - val_loss: 0.3507 - val_accuracy: 0.8936\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 61s 36ms/step - loss: 0.2007 - accuracy: 0.9286 - val_loss: 0.3387 - val_accuracy: 0.8998\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 60s 35ms/step - loss: 0.1950 - accuracy: 0.9302 - val_loss: 0.3263 - val_accuracy: 0.9064\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 59s 34ms/step - loss: 0.1917 - accuracy: 0.9319 - val_loss: 0.3474 - val_accuracy: 0.9036\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.1837 - accuracy: 0.9338 - val_loss: 0.3560 - val_accuracy: 0.9038\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.1839 - accuracy: 0.9349 - val_loss: 0.3584 - val_accuracy: 0.8992\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 61s 35ms/step - loss: 0.1796 - accuracy: 0.9368 - val_loss: 0.3512 - val_accuracy: 0.9040\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 63s 37ms/step - loss: 0.1772 - accuracy: 0.9371 - val_loss: 0.3931 - val_accuracy: 0.8962\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 66s 39ms/step - loss: 0.1766 - accuracy: 0.9377 - val_loss: 0.3778 - val_accuracy: 0.9004\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 63s 36ms/step - loss: 0.1676 - accuracy: 0.9394 - val_loss: 0.3791 - val_accuracy: 0.9058\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 61s 36ms/step - loss: 0.1681 - accuracy: 0.9417 - val_loss: 0.3826 - val_accuracy: 0.9062\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 62s 36ms/step - loss: 0.1626 - accuracy: 0.9443 - val_loss: 0.3716 - val_accuracy: 0.9022\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 62s 36ms/step - loss: 0.1612 - accuracy: 0.9433 - val_loss: 0.3920 - val_accuracy: 0.8990\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 62s 36ms/step - loss: 0.1593 - accuracy: 0.9445 - val_loss: 0.4041 - val_accuracy: 0.8972\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 62s 36ms/step - loss: 0.1541 - accuracy: 0.9463 - val_loss: 0.3827 - val_accuracy: 0.9040\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 64s 37ms/step - loss: 0.1537 - accuracy: 0.9455 - val_loss: 0.4012 - val_accuracy: 0.9006\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 63s 37ms/step - loss: 0.1488 - accuracy: 0.9476 - val_loss: 0.3915 - val_accuracy: 0.9070\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 66s 38ms/step - loss: 0.1516 - accuracy: 0.9487 - val_loss: 0.3919 - val_accuracy: 0.9012\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 63s 36ms/step - loss: 0.1457 - accuracy: 0.9495 - val_loss: 0.4380 - val_accuracy: 0.8950\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 62s 36ms/step - loss: 0.1419 - accuracy: 0.9496 - val_loss: 0.4161 - val_accuracy: 0.9040\n"
     ]
    }
   ],
   "source": [
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "history = model3.fit(a_train, b_train, epochs=40,\n",
    "                    validation_data=(a_valid, b_valid))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67b8b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  94.95818018913269\n",
      "Validation Accuracy:  90.39999842643738\n",
      "Test Accuracy:  89.45000171661377\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = model3.evaluate(a_test, b_test, verbose=0)\n",
    "print(\"Train Accuracy: \", history.history['accuracy'][-1] * 100)\n",
    "print(\"Validation Accuracy: \", history.history['val_accuracy'][-1] * 100)\n",
    "print(\"Test Accuracy: \", test_accuracy * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
